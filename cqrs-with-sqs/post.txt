No primeiro post da série de posts que abordam as diferents formas de se implementar o padrão CQRS na AWS, abordarei a forma mais simples do padrão, que é sincronizar os serviços de comando e consulta por meio do <a href="https://aws.amazon.com/sqs">Amazon SQS</a>. Ao se trabalhar com aplicações que lidam com dados complexos, seja em um ambiente de microsserviços, no qual cada microsserviço tem seu próprio banco de dados, ou mesmo em aplicações monolíticas, pode ser que o modelo do banco de dados no qual os dados residem não esteja no formato ideal para leitura, devido a <i>joins</i> complexos, por exemplo, que podem resultar em consultas que demoram mais do que se pode esperar, ou que o usuário esteja disposto a esperar. Nesses casos, o padrão arquitetural CQRS pode ser usado.

Nesta série de seis blog posts, explicarei a história desse padrão, a motivação por trás dele e como ele pode ser implementado com diferentes serviços da AWS. As quatro primeiras partes demonstrarão o <a href="https://aws.amazon.com/rds/aurora">Amazon Aurora for PostgreSQL</a> como banco de dados do serviço de <i>command</i> (comando) e o <a href="https://aws.amazon.com/elasticache">Amazon Elasticache for Redis</a> como banco de dados do serviço de <i>query</i> (consultas). Nesta primeira parte, demonstrarei o padrão CQRS em sua forma mais simples. Na segunda parte, começaremos a usar o padrão <i>Transactional Outbox</i> (em português, algo como "caixa de saída transacional") para publicar eventos do serviço de comando para alimentar o serviço de consultas, usando a técnica <i>Polling Publisher</i>. Na terceira e quarta partes, também usaremos o padrão <i>Transactional Outbox</i>, mas usando a técnica <i>Transaction Log Tailing</i> (em português, algo como "ler a cauda/fim do log de transações).

Na quinta parte, demonstrarei como podemos implementar o CRQS com o <a href="https://aws.amazon.com/dynamodb">Amazon DynamoDB</a> sendo o banco de dados do serviço de comando e o Amazon Aurora for Postgres como banco do serviço de consultas. Para finalizar, apresentarei uma conclusão e uma comparação de todas as técnicas na sexta parte.
<h2>Introdução</h2>
Em 1988, Bertrand Meyer introduziu a ideia de <a href="https://martinfowler.com/bliki/CommandQuerySeparation.html">Command-Query Separation</a>, ou CQS, em seu livro <a href="https://dl.acm.org/doi/book/10.5555/534929">Object-Oriented Software Construction</a>, a ser aplicado a softwares orientados a objetos. A ideia fundamental é que os métodos de um objeto devem ser divididos em duas categorias: métodos que apenas retornam valor e não alteram o estado e métodos que apenas alteram o estado e não retornam nenhum valor. Cada método deve pertencer a uma dessas categorias, mas não a ambas. A vantagem é que temos uma clara separação de métodos, e os métodos que realizam consultas podem ser invocados de forma idempotente. Na prática, essa regra se aplica à maioria dos casos, mas não a todos. Usando os métodos da estrutura de dados da pilha como exemplo, seu método pop() retorna o objeto no topo da pilha e também o exclui, o que o torna um método que recupera um valor e altera o estado.

Inspirado pelo CQS e seus benefícios, Greg Young apresentou pela primeira vez a ideia do padrão Command-Query Responsibility Segregation, ou CQRS, em uma palestra apresentada por ele na QCon San Francisco, em 2006. Foi, no entanto, somente após <a href="https://qconsf.com/sf2007/sf2007/presentation/Scaling%2bDomain%2bDriven%2bDesign.html">uma segunda palestra apresentada por ele, na QCon San Francisco, em 8 de novembro de 2007</a>, que a ideia começou a tomar tração. A ideia geral é que nossa solução possa ser estruturada de forma que haja dois serviços, sendo um responsável pelas operações de escrita (comandos) e outro pelas operações de leitura (consultas).

Há casos em que o banco de dados sendo utilizado não favorece as operações de leitura, por exemplo, um banco de dados relacional que precisa realizar vários <i>joins</i> e outras agregações para retornar as informações necessárias, introduzindo latência indesejada no tempo de resposta da aplicação. Nesses casos, podemos criar um serviço que receba as operações de escrita (comandos), armazena dados em seu banco de dados, e publica eventos que são capturados pelo serviço responsável pelas operações de consulta/leitura, que, por sua vez, preenche seu banco de dados de forma assíncrona com as novas informações.

Os benefícios de se ter dois serviços separados para escrita e consultas são os seguintes:
<ul>
 	<li>Escalabilidade independente. Como os serviços existem de forma independente, é possível escalá-los conforme necessário. Se a aplicação receber mais solicitações de alteração de estado (comandos), poderemos ter mais servidores ou <i>containers</i> lidando com elas. Se o banco de dados sendo utilizado for um banco de dados relacional, como o Amazon Aurora, precisaremos encontrar o tamanho certo da instância de escrita e, para isso, poderemos usar métricas como IOPS, CPU Utilization e Throughput, além de analisar como as escritas são feitas no banco de dados. Dependendo do padrão de escrita, por exemplo, se houver picos durante um determinado período de tempo e períodos mais longos de escrita muito baixos, pode ser o caso de se fazer uso de serverless, que está disponível para o Amazon Aurora.</li>
 	<li>Banco de dados para propósito específico. Nem sempre o modelo de dados ou banco de dados sendo utilizado pode nos servir conforme precisamos. Pode ser que o modelo de dados reflita um caso de uso real que, por exemplo, não favoreça leituras ou que o banco de dados usado não permita responder facilmente a perguntas específicas. Nesses casos, podemos usar o banco de dados mais apropriado para operações de escrita e consulta separadamente.</li>
 	<li>Tecnologias e ciclo de vida independentes. Haverá dois serviços independentes lidando com comandos e consultas, e cada serviço poderá ser construído com a tecnologia que melhor atenda cada necessidade. Por exemplo, podemos ter o serviço de comando implementado em Java e o serviço de consulta implementado em Python. Da mesma forma, cada serviço pode ter seu próprio ambiente de execução, como o serviço de comando executado como uma função <a href="https://aws.amazon.com/lambda">AWS Lambda</a> e o serviço de consulta executado como um container no Amazon EKS. Cada serviço também pode ter seu próprio ciclo de vida e pipeline de implantação.</li>
</ul>
Ter dois bancos de dados separados e dois serviços separados atendendo a diferentes solicitações introduz mais complexidade em um sistema, o que só compensa quando precisamos de escalabilidade diferente ou bancos de dados diferentes para atender a comandos e consultas. Se a escalabilidade for a única preocupação, podemos ter apenas um banco de dados atendendo a propósitos e a diferentes serviços que podem ser escalados de forma independente. Nesse caso, precisaríamos apenas pensar em como evitar que o banco de dados tivesse que lidar com várias consultas, como com réplicas de leitura.

Se o banco de dados for um <a href="https://aws.amazon.com/rds">Amazon RDS</a>, o serviço que atende a consultas pode ler réplicas de leitura. Se um banco de dados diferente para fins de leitura for a única preocupação (como em um caso em que se deseja manter informações pré-computadas em um cache de segundo nível, como o Amazon Elasticache for Redis), podemos ter apenas um serviço acessando um banco de dados diferente a cada necessidade, introduzindo uma fila que recebe um evento após uma inserção e que é lida por um componente que atualiza o banco de dados que atende a consultas.

Se precisarmos de dois serviços separados e dois bancos de dados diferentes para atender a comandos e consultas, há algumas opções que podemos usar para implementar o CQRS na AWS. Vamos dar uma olhada na forma mais simples.
<h2>Caso de uso: Amazon Aurora for Postgres como banco de dados do serviço de comando e Amazon Elasticache for Redis como banco de dados do serviço de consultas, usando o Amazon SQS</h2>
No primeiro caso que abordarei nesta série de blog posts, temos o Amazon Aurora for Postgres como banco de dados do serviço que recebe comandos e o Amazon Elasticache for Redis como banco de dados do serviço que recebe consultas. O banco de dados Amazon Aurora conterá informações relacionadas a clientes, produtos e pedidos, e o banco de dados Amazon Elasticache for Redis conterá informações pré-computadas relacionadas a clientes. Para testar a arquitetura, usaremos dois endpoints, um para salvar pedidos e outro para recuperar informações relacionadas a clientes.
<h2>Visão Geral da Solução</h2>
A opção mais simples é publicar um evento em uma fila do Amazon SQS depois de atualizar o banco de dados do serviço de comando. A partir daí, os eventos serão recuperados por um componente que possa realizar computação (como uma função AWS Lambda) e as informações pré-computadas relacionadas ao cliente serão atualizadas no Redis. Outra opção seria colocar um evento em um tópico do <a href="https://aws.amazon.com/sns">Amazon SNS</a> em vez de em uma fila do Amazon SQS, para que ele pudesse notificar vários destinatários sobre as novas informações inseridas no Amazon Aurora.

É importante observar que, embora esse exemplo use o <a href="https://aws.amazon.com/api-gateway">Amazon API Gateway</a>, encaminhando mensagens para uma função Lambda, os serviços de comando e consultas podem ser implementados por qualquer componente computacional. Poderia ser, por exemplo, um container no <a href="https://aws.amazon.com/eks">Amazon EKS</a> como serviço de comando e um container no <a href="https://aws.amazon.com/ecs">Amazon ECS</a> como serviço de consulta. O aspecto mais importante dessa implementação é fazer com que o serviço de comando publique eventos que alimentem o banco de dados do serviço de consulta.

Essa primeira solução também considera uma <i>dead-letter queue</i>. Quando uma mensagem é processada com sucesso por uma função Lambda, ela remove automaticamente a mensagem processada da fila. Se a mensagem não puder ser processada pela função Lambda devido, por exemplo, a uma exceção, ela se tornará visível novamente na fila e o número de vezes que essa mensagem foi recebida na fila aumentará em 1. Quando esse contador atinge o máximo de recebimentos, configurado quando a <i>dead-letter queue</i> foi configurada na fila principal, essa mensagem é movida para a <i>dead-letter queue</i>, para que possa ser processada por outros meios, como acionar um alarme, enviar um e-mail, inserir um registro em outro banco de dados e assim por diante. Para manter esse exemplo simples, esses outros mecanismos foram omitidos.

Outra solução possível seria fazer com que o Amazon API Gateway colocasse uma mensagem diretamente em uma fila do Amazon SQS em vez de invocar uma função Lambda. Na fila, poderíamos fazer com que outro componente (como uma função Lambda) recuperasse a mensagem. Nesse caso, se uma exceção fosse lançada na função Lambda, a mensagem não seria removida da fila até que o número de recebimentos fosse alcançado. Teríamos que controlar o tratamento dessas mensagens com padrões de resiliência, como o <i>retry</i>, <i>circuit breaker</i>, <i>exponential backoff</i> e também uma <i>dead-letter queue</i>. Se o caso de uso sendo implementado exigisse um processamento síncrono, essa ideia não seria uma opção.

[caption id="attachment_13158" align="alignnone" width="760"]<img class="wp-image-13158" title="Arquitetura da solução" src="https://d2908q01vomqb2.cloudfront.net/d435a6cdd786300dff204ee7c2ef942d3e9034e2/2024/03/27/Diagrams-Aurora-SQS-Port.drawio-1.png" alt="Imagem demonstrando a arquitetura proposta, tendo o Amazon Aurora for Postres como banco de dados do serviço de comando, e o Amazon Elasticache for Redis como banco de dados do serviço de consultas. A sincronização de dados entre os dois bancos é feito por meio da publicação de um evento pelo serviço de comando em uma fila do Amazon SQS, que por sua vez é lida por uma função Lambda que atualiza o Amazon Elasticache for Redis." width="760" height="474"/> Figura 1. Arquitetura proposta, tendo o Amazon Aurora for Postgres como banco de dados do serviço de comando, e o Amazon Elasticache for Redis como banco de dados do serviço de consultas.[/caption]

O ponto forte dessa arquitetura é sua simplicidade. Em termos simples, usamos uma fila para enviar dados do lado do serviço de comando para o lado do serviço de consultas. Assim que recebemos um pedido na função OrderReceiverLambda e o salvamos no banco de dados Postgres, publicamos um evento em uma fila SQS. Poderíamos até mesmo preparar as informações pré-computadas relacionadas ao cliente nessa função do Lambda, mas ela estaria fazendo mais do que deveria, contradizendo o <a href="https://blog.cleancoder.com/uncle-bob/2014/05/08/SingleReponsibilityPrinciple.html">Single Responsibility Principle</a> (Princípio de Responsabilidade Única). Além disso, se não conseguíssemos atualizar o cache do Redis por algum motivo (pode ser que ele estivesse sendo atualizado para uma nova versão, por exemplo), perderíamos essas informações. Com uma fila, podemos processar esse evento posteriormente, mesmo que o cache do Redis esteja temporariamente indisponível.

Nosso objetivo aqui é levar as alterações do Amazon Aurora for Postgres para o Amazon Elasticache for Redis de forma confiável. O problema é que, diferentemente do Amazon DynamoDB, <a href="https://aws.amazon.com/documentdb">Amazon DocumentDB</a> ou <a href="https://aws.amazon.com/neptune">Amazon Neptune</a>, o Amazon Aurora não tem uma forma nativa de publicar eventos e, portanto, a transação (por ser um banco de dados relacional que suporta transações ACID) é separada da publicação do evento.

Há pontos a serem considerados nessa solução. A primeira é que o commit da transação na OrderReceiverLambda é separado da publicação do evento. Vamos considerar um caso em que uma transação é confirmada (commited) e, em seguida, um evento é enviado para uma fila do Amazon SQS. Se por algum motivo houver um problema ao colocar o evento na fila do Amazon SQS, os dois bancos de dados ficarão fora de sincronia. Se a publicação do evento na fila do Amazon SQS acontecer dentro da transação, o que pode acontecer é que o evento pode ser publicado na fila do Amazon SQS, o banco de dados Redis será atualizado, mas a transação poderá, por algum motivo, não ser confirmada, deixando os dois bancos de dados também fora de sincronia. Nessa mesma situação, se houver um problema ao publicar o evento na fila do Amazon SQS, a transação será revertida (rolledback) não por causa de um problema com os dados em si, mas porque houve um problema com um componente externo.

Essa solução considera uma fila standard do Amazon SQS, o que significa que podemos receber quase que um número ilimitado de mensagens por segundo. Nesse caso, não precisamos que as mensagens sejam ordenadas, então podemos usar uma fila standard em vez de uma fila FIFO. Se usássemos uma fila FIFO, teríamos o limite de no máximo 300 mensagens por segundo. Considerando o exemplo acima, a mensagem a ser colocada na fila do Amazon SQS pelo OrderReceiverLambda pode se parecer com o seguinte:
<pre><code class="lang-python">select_statement = "select name, email from public.client where id = %s"
# Select the client with the id of the client placing the order
cur.execute(select_statement, str(event["id_client"]))
client = cur.fetchone()

order_event = {
    "messageId": str(uuid.uuid4()),
    "id_client": event["id_client"],
    "name": client[0],
    "email": client[1],
    "order_total": order_total,
    "event_date": now
}</code></pre>
Enquanto as filas FIFO têm uma semântica de entrega exactly-once, as filas standard têm uma semântica de entrega at-least-once e, portanto, precisamos garantir que a mesma mensagem não seja processada duas vezes. Uma forma é adicionar um campo id à mensagem a ser colocada na fila e verificar esse id antes de processá-la. E como já estamos usando o Amazon Elasticache for Redis, podemos adicionar uma entrada ao nosso cache, cuja chave será o id da mensagem, com um tempo de expiração de cinco minutos. E antes de adicionarmos ou atualizarmos a chave que contém o valor das informações relacionadas ao cliente, verificamos se o id da mensagem já existe como uma chave em nosso cache. Caso não exista, processamos a mensagem; caso contrário, simplesmente a ignoramos, pois será uma mensagem duplicada.

Outra coisa a considerar é que não podemos reexecutar os eventos, o que poderia ser interessante se quiséssemos reproduzir um bug ou carregar outro banco de dados, por exemplo. Para resolver esses problemas, o padrão Transactional Outbox pode ajudar. Mas essa é a abordagem que vamos explorar nos próximos três posts desta série!
<h2>Executando o Exemplo</h2>
Para executar o exemplo, o leitor deverá ter uma conta na AWS e um usuário com permissões de admin. Depois, basta executar o passo-a-passo fornecido no <a href="https://github.com/aws-samples/cqrs-on-aws/tree/main/cqrs_with_sqs">repositório de códigos desta série de blog posts sobre CQRS</a>, no AWS Samples, hospedado no Github. Ao executar o passo-a-passo, os leitores terão a infraestrutura aqui apresentada nas suas próprias contas.

O exemplo contém dois endpoints, sendo um para receber informações relacionadas a pedidos (representando o nosso serviço de comando) e outro para recuperar informações relacionadas a clientes (representando nosso serviço de consultas). Para verificar se tudo funcionou corretamente, vá até o Amazon API Gateway e, na lista de APIs, entre na API "OrdersAPI", e depois em Stages. Haverá somente uma stage chamada "prod". Recupere o valor do campo Invoke URL e acrescente “/orders”. Esse é o endpoint que recebe informações relacionadas a pedidos.

Vamos realizar uma requisição POST para esse endpoint. Podemos usar qualquer ferramenta para efetuar requisições para esse endpoint, como cURL ou Postman. Como esse endpoint está protegido, também precisamos adicionar basic authentication. Se você estiver usando o Postman, será necessário recuperar o nome de usuário e senha gerados na construção da infraestrutura. No Amazon API Gateway, vá até API Keys e copie o valor da coluna "API key" de "admin_key". Esse valor contém nome de usuário e senha separados pelo caracter ":", porém está codificado em Base64. Decodifique o valor (utilizando alguma ferramenta online, ou o próprio comando "base64" do Linux). O nome de usuário está à esquerda do caracter ":", e a senha está à direita. Adicione uma Authorization do tipo Basic Auth e preencha os campos “Username” e “Password" com os valores recuperados. Adicione também um header “Content-Type”, com o valor “application/json”.

Se você estiver usando, por exemplo, cURL, não será necessário decodificar o valor da API key. Basta adicionar um header "Authorization" com o valor "Basic &lt;valor da api key copiado da coluna API key&gt;". Adicione também um header“Content-Type”, com o valor “application/json”.

O payload para efetuar requisições para esse endpoint é o seguinte:
<pre><code class="lang-json">{
    "id_client": 1,
    "products": [{
        "id_product": 1,
        "quantity": 1
    }, {
        "id_product": 2,
        "quantity": 3
    }]
}</code></pre>
Isso representa um pedido que o cliente com id 1 fez, contendo produtos com ids 1 e 2. O total desse pedido é de $3000. Todas essas informações serão armazenadas no Amazon Aurora. Ao efetuar essa requisição POST, se tudo funcionou conforme o esperado, você deve ver o seguinte resultado:
<pre><code class="lang-json">{
    "statusCode": 200,
    "body": "Order created successfully!"
}</code></pre>
Agora vamos verificar se as informações relacionadas ao cliente foram enviadas para o Redis. Ao endpoint do API Gateway, que foi recuperado anteriormente, acrescente “/clients/1". Esse é o endpoint que recupera informações relacionadas ao cliente. Vamos efetuar uma solicitação GET para esse endpoint. Assim como fizemos com o endpoint “/orders”, precisamos adicionar basic authentication. Siga as etapas explicadas anteriormente e efetue a requisição GET. Se tudo funcionou conforme o esperado, você verá uma saída semelhante à seguinte:
<pre><code class="lang-json">{
    "name": "Bob",
    "email": "bob@anemailprovider.com",
    "total": 3000.0,
    "last_purchase": 1700836837
}</code></pre>
Isso significa que conseguimos alimentar com sucesso o Amazon Elasticache for Redis com informações prontas para serem recuperadas, enquanto as mesmas informações estão no Amazon Aurora for Postgres, em outro formato.
<h2>Limpando os Recursos</h2>
Para excluir a infraestrutura criada, no mesmo diretório em que a infraestrutura foi criada, basta executar o comando "cdk destroy" e confirmar. A deleção leva aproximadamente 10 minutos.
<h2>Conclusão</h2>
Nesta blog post, demonstrei como podemos implementar o padrão CQRS com serviços AWS, em sua forma mais simples. A vantagem desse padrão é que podemos ter serviços diferentes servindo comandos e consultas, além de bancos de dados diferentes, cada um com finalidades diferentes.

Os serviços de comando e consulta são independentes e, portanto, podem ser escalados de forma independente, ter bancos de dados diferentes e também regras diferentes, como segurança. Embora eu tenha apresentado neste blog post o Amazon Aurora como o banco de dados para o serviço de comando e o Amazon Elasticache for Redis como o banco de dados para o serviço de consultas, a ideia é que possamos ter o banco de dados que melhor atenda a cada propósito.

Essa é a forma mais simples de CQRS e tem seus prós e contras. A grande vantagem desta solução é sua simplicidade, e sua grande desvantagem é que eventos podem ser perdidos e também não podem ser reprocessados. Nos próximo postdesta série, explorarei uma técnica que faz uso do padrão Transactional Outbox para enviar de forma confiável informações do serviço de comando para o serviço de consultas, mais especificamente, com a técnica de <i>Polling Publisher</i>.
<h2>Sobre o Autor</h2>
<table width="100%">
<tbody>
<tr>
<td valign="top" align="left" width="170"><img class="size-full wp-image-13203 alignleft" src="https://d2908q01vomqb2.cloudfront.net/d435a6cdd786300dff204ee7c2ef942d3e9034e2/2024/03/28/perillo_author.jpeg" alt="" width="160" height="160"/></td>
<td valign="top" align="left">Roberto Perillo é arquiteto de soluções enterprise da AWS Brasil especialista em <em>serverless,</em> e atua na indústria de software desde 2001. Possui graduação em Ciência da Computação, especialização em Engenharia de Software e mestrado em Ciência da Computação. Um eterno estudante. Nas horas vagas, gosta de tocar guitarra e jogar futebol de botão com seu filho, Lorenzo!</td>
</tr>
</tbody>
</table>
<br/>